{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidteng/anaconda3/envs/wsd/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, torch\n",
    "import lightning  as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cwb2LocModel(L.LightningModule):\n",
    "    def __init__(self, input_dim=7, hidden_dim=128, num_layers=2, output_dim=1, learning_rate=1e-3, delta=1.0):\n",
    "        super(Cwb2LocModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.delta = delta  # 動態設置 delta\n",
    "\n",
    "        # 定義 LSTM 層\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.2, bidirectional=True)\n",
    "\n",
    "        # 定義全連接層\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim // 4)\n",
    "        self.fc2 = nn.Linear(hidden_dim // 4, input_dim)\n",
    "        self.fc3 = nn.Linear(input_dim, 1)\n",
    "\n",
    "        # 定義損失函數（Huber Loss）\n",
    "        # self.criterion = nn.HuberLoss(delta=self.delta)\n",
    "        # self.criterion = nn.MSELoss()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        # self.criterion = log_cosh_loss\n",
    "\n",
    "    def log_cosh_loss(y_pred, y_true):\n",
    "        loss = torch.mean(torch.log(torch.cosh(y_pred - y_true)))\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隱藏狀態和細胞狀態\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(self.device)\n",
    "        residual = x\n",
    "        \n",
    "        # 前向傳播 LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 通過全連接層得到最終輸出\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out += residual\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)  # 使用 Huber Loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)  # 使用 Huber Loss\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=1e-2\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.9)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9715079916608751, 0.9635163307852679, 0.9555246699096589, 0.9475330090340517, 0.9395413481584427, 0.9315496872828355, 0.9235580264072265, 0.9155663655316193, 0.9075747046560103, 0.8995830437804031, 0.8915913829047959, 0.8835997220291869, 0.8756080611535797, 0.8676164002779707, 0.8596247394023635, 0.8516330785267545, 0.8436414176511473, 0.8356497567755383, 0.8276580958999311, 0.8196664350243221, 0.8116747741487149, 0.8036831132731059, 0.7956914523974987, 0.7876997915218897, 0.7797081306462825, 0.7717164697706735, 0.7637248088950663, 0.7557331480194573, 0.7477414871438501, 0.7397498262682412, 0.7317581653926339, 0.723766504517025, 0.7157748436414177, 0.7077831827658088, 0.6997915218902016, 0.6917998610145943, 0.6838082001389854, 0.6758165392633781, 0.6678248783877692, 0.659833217512162, 0.651841556636553, 0.6438498957609458, 0.6358582348853368, 0.6278665740097296, 0.6198749131341206, 0.6118832522585134, 0.6038915913829044, 0.5958999305072972, 0.5879082696316882, 0.579916608756081, 0.571924947880472, 0.5639332870048648, 0.5559416261292558, 0.5479499652536486, 0.5399583043780396, 0.5319666435024324, 0.5239749826268234, 0.5159833217512162, 0.5079916608756072, 0.5]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# 定义月份和特征\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
    "features = ['rain', 'raintime', 'solarpower', 'suntime', 'temp', 'uv']\n",
    "\n",
    "# 初始化 cwb_data_dict，四层嵌套：特征 -> 月份 -> 天数 -> 时间索引\n",
    "# 时间索引初始为小时（0-23），插值后为分钟（0-1439）\n",
    "cwb_data_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "# 读取气象数据\n",
    "for month in months:\n",
    "    for feature in features:\n",
    "        csv_path = f'../cwbdata/{month}/{feature}-{month}.csv'\n",
    "        try:\n",
    "            with open(csv_path, 'r', encoding='utf-8') as csv_file:\n",
    "                reader = csv.reader(csv_file)\n",
    "                for row in reader:\n",
    "                    if row[0].isdigit():\n",
    "                        day = int(row[0])\n",
    "                        for hour_index, value in enumerate(row[1:], start=0):\n",
    "                            if hour_index < 24:\n",
    "                                try:\n",
    "                                    cwb_data_dict[feature][int(month)][day][hour_index] = float(value)\n",
    "                                except (ValueError, TypeError):\n",
    "                                    cwb_data_dict[feature][int(month)][day][hour_index] = None  # 标记为无效值\n",
    "        except FileNotFoundError:\n",
    "            print(f\"文件未找到: {csv_path}\")\n",
    "\n",
    "# 插值函数\n",
    "def interpolate_feature(feature_data):\n",
    "    \"\"\"\n",
    "    对某一天的一个特征进行插值，从小时级别扩展到分钟级别。\n",
    "    feature_data: dict, {hour: value} 表示该天的一个特征数据\n",
    "    返回插值后的 1440 个分钟值\n",
    "    \"\"\"\n",
    "    hours = sorted(feature_data.keys())  # 获取所有小时索引\n",
    "    values = [feature_data[hour] for hour in hours]  # 获取每小时的值\n",
    "\n",
    "    # 处理无效值：用前后有效值的平均值填充\n",
    "    for i in range(len(values)):\n",
    "        if values[i] is None:\n",
    "            prev_valid = next((values[j] for j in range(i - 1, -1, -1) if values[j] is not None), None)\n",
    "            next_valid = next((values[j] for j in range(i + 1, len(values)) if values[j] is not None), None)\n",
    "            if prev_valid is not None and next_valid is not None:\n",
    "                values[i] = (prev_valid + next_valid) / 2\n",
    "            elif prev_valid is not None:\n",
    "                values[i] = prev_valid\n",
    "            elif next_valid is not None:\n",
    "                values[i] = next_valid\n",
    "            else:\n",
    "                values[i] = 0.0  # 如果前后都没有有效值，填充为 0.0\n",
    "\n",
    "    # 线性插值\n",
    "    x = np.array(hours)  # 小时索引\n",
    "    y = np.array(values)  # 每小时的值\n",
    "    x_minute = np.linspace(0, 23, 1440)  # 每分钟的索引\n",
    "    interpolated_values = np.interp(x_minute, x, y)  # 插值到分钟级别\n",
    "\n",
    "    return interpolated_values\n",
    "\n",
    "# 对每个特征的每一天数据进行插值并更新到字典中\n",
    "for feature in features:\n",
    "    for month in cwb_data_dict[feature]:\n",
    "        for day in cwb_data_dict[feature][month]:\n",
    "            # 插值数据\n",
    "            hourly_data = cwb_data_dict[feature][month][day]\n",
    "            interpolated_values = interpolate_feature(hourly_data)\n",
    "            \n",
    "            # 将插值结果以每小时为单位存储到字典中\n",
    "            for hour in range(24):\n",
    "                start_idx = hour * 60\n",
    "                end_idx = (hour + 1) * 60\n",
    "                cwb_data_dict[feature][month][day][hour] = interpolated_values[start_idx:end_idx].tolist()\n",
    "\n",
    "# 验证插值结果\n",
    "for feature in features:\n",
    "    for month in cwb_data_dict[feature]:\n",
    "        for day in cwb_data_dict[feature][month]:\n",
    "            for hour in cwb_data_dict[feature][month][day]:\n",
    "                assert len(cwb_data_dict[feature][month][day][hour]) == 60, \\\n",
    "                    f\"插值结果错误：{feature}, 月份 {month}, 日期 {day}, 小时 {hour}\"\n",
    "                assert all(isinstance(value, float) for value in cwb_data_dict[feature][month][day][hour]), \\\n",
    "                    f\"存在非 float 值：{feature}, 月份 {month}, 日期 {day}, 小时 {hour}\"\n",
    "\n",
    "print((cwb_data_dict['rain'][2][22][23]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_cwb_data(month, day, loc, features): #0101\n",
    "    test_x = []\n",
    "    for hour in range(7, 17):\n",
    "        for minute in range(60):\n",
    "            try:\n",
    "                # 確保索引不超出範圍\n",
    "                newx = []\n",
    "                for f in features:\n",
    "                    newx.append(cwb_data_dict[f][int(month)][int(day)][int(hour)][minute])\n",
    "                newx.append(loc)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # 如果出現錯誤，使用默認值\n",
    "                newx = [0.0] * (len(features) + 1)\n",
    "            test_x.append(\n",
    "                newx\n",
    "            )\n",
    "    for minute in range(30):\n",
    "        try:\n",
    "            # 確保索引不超出範圍\n",
    "            newx = []\n",
    "            for f in features:\n",
    "                newx.append(cwb_data_dict[f][int(month)][int(day)][int(17)][minute])\n",
    "            newx.append(loc)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # 如果出現錯誤，使用默認值\n",
    "            newx = [0.0] * (len(features) + 1)\n",
    "        test_x.append(\n",
    "            newx\n",
    "        )\n",
    "    return test_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_at_time(y_hat_original, hour, minute):\n",
    "    hour = int(hour)\n",
    "    minute = int(minute)\n",
    "    if hour < 7 or hour > 18:\n",
    "        raise ValueError(\"小時超出範圍，必須在 [7, 18] 之間\")\n",
    "    if minute < 0 or minute > 59:\n",
    "        raise ValueError(\"分鐘超出範圍，必須在 [0, 59] 之間\")\n",
    "    index = (hour - 7) * 60 + minute\n",
    "    \n",
    "    if index >= len(y_hat_original):\n",
    "        raise IndexError(f\"索引 {index} 超出 y_hat_original 長度 {len(y_hat_original)}\")\n",
    "    # 返回該時間點的預測值\n",
    "    return list(y_hat_original[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cwb2LocModel(\n",
       "  (lstm): LSTM(7, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=7, bias=True)\n",
       "  (fc3): Linear(in_features=7, out_features=1, bias=True)\n",
       "  (criterion): L1Loss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f'./saved_models_v3/best-checkpoint-6-B-best.ckpt'\n",
    "model = Cwb2LocModel.load_from_checkpoint(model_path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  # 將模型移動到 GPU（如果可用）\n",
    "model.eval()  # 切換模型到評估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_sample_output(id, features, model_cls=Cwb2LocModel):\n",
    "    # 解析 ID\n",
    "    month = id[4:6]\n",
    "    day = id[6:8]\n",
    "    hour = id[8:10]\n",
    "    minute = id[10:12]\n",
    "    loc = int(id[12:])\n",
    "    \n",
    "    # 加載標準化器\n",
    "    with open(f'./scalar_v2/x_scaler.pkl', 'rb') as f:\n",
    "        x_scaler = pickle.load(f)\n",
    "    with open(f'./scalar_v2/y_scaler.pkl', 'rb') as f:\n",
    "        y_scaler = pickle.load(f)\n",
    "    \n",
    "    # 構建測試數據\n",
    "    test_x = collate_cwb_data(month, day, loc, features)  # 獲取測試數據 (shape: [max_len, num_features])\n",
    "    test_x = np.array(test_x, dtype=np.float32)  # 確保數據是 NumPy 格式\n",
    "    num_samples, num_features = test_x.shape\n",
    "    test_x = test_x.reshape(-1, num_features)  # 展平成 2D\n",
    "\n",
    "    # 正規化數據\n",
    "    test_x_normalized = x_scaler.transform(test_x)  # 對數據進行標準化\n",
    "    test_x_normalized = test_x_normalized.reshape(1, -1, num_features)  # 添加 batch 維度\n",
    "    \n",
    "    # 將數據轉換為 PyTorch 張量並移動到相應設備\n",
    "    test_x_tensor = torch.tensor(test_x_normalized, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 使用模型進行預測\n",
    "    with torch.no_grad():  # 禁用梯度計算以加速推理\n",
    "        y_hat = model(test_x_tensor)  # 模型預測\n",
    "        y_hat = y_hat.cpu().numpy()  # 將張量轉換為 NumPy 格式\n",
    "        y_hat = y_hat.reshape(-1, y_hat.shape[-1])  # 展平成 2D\n",
    "    \n",
    "    # 反正規化輸出\n",
    "    y_hat_original = y_scaler.inverse_transform(y_hat)  # 反正規化\n",
    "    preds = []\n",
    "    for i in range(int(minute), int(minute)+10):\n",
    "        preds.append(get_prediction_at_time(y_hat_original, hour, i))\n",
    "    # print(len(preds))\n",
    "    return sum([item[0] for item in preds])/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def fill_csv_with_predictions(csv_path, output_csv_path, model_cls, features):\n",
    "    import pandas as pd\n",
    "\n",
    "    # 讀取 CSV 文件\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 檢查是否包含必要的列\n",
    "    if '序號' not in df.columns or '答案' not in df.columns:\n",
    "        raise ValueError(\"CSV 文件必須包含 '序號' 和 '答案' 列\")\n",
    "    \n",
    "    # 遍歷每個序號進行預測\n",
    "    predictions = []\n",
    "    for seq_id in tqdm(df['序號'], desc=\"Processing Predictions\", unit=\"sample\"):\n",
    "        try:\n",
    "            # 使用模型進行預測\n",
    "            prediction = get_single_sample_output(str(seq_id), features, model_cls=model_cls)\n",
    "            \n",
    "            # 確保 prediction 是 float\n",
    "            if isinstance(prediction, (float, np.float32, np.float64)):\n",
    "                if prediction >= 0:\n",
    "                    predictions.append(prediction)\n",
    "                else:\n",
    "                    predictions.append(0.0)\n",
    "            else:\n",
    "                raise ValueError(f\"無效的輸出類型: {type(prediction)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"序號 {seq_id} 預測失敗，錯誤: {e}\")\n",
    "            predictions.append(\"ERROR\")  # 如果失敗則標記為 ERROR\n",
    "    \n",
    "    # 將預測結果填入答案列\n",
    "    df['答案'] = predictions\n",
    "    \n",
    "    # 將結果保存為新的 CSV 文件\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"預測結果已保存到 {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rain', 'raintime', 'solarpower', 'suntime', 'temp', 'uv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1703126\n"
     ]
    }
   ],
   "source": [
    "print(get_single_sample_output('20240101172001', features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Predictions:   0%|          | 0/9600 [00:00<?, ?sample/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Predictions: 100%|██████████| 9600/9600 [01:02<00:00, 152.90sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測結果已保存到 ./upB-3.csv\n"
     ]
    }
   ],
   "source": [
    "fill_csv_with_predictions('./up.csv', './upB-3.csv', Cwb2LocModel, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
