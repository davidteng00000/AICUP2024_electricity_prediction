{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidteng/anaconda3/envs/wsd/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, torch\n",
    "import lightning  as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cwb2LocModel(L.LightningModule):\n",
    "    def __init__(self, input_dim=7, hidden_dim=128, num_layers=2, output_dim=1, learning_rate=1e-3, delta=1.0):\n",
    "        super(Cwb2LocModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.delta = delta  # 動態設置 delta\n",
    "\n",
    "        # 定義 LSTM 層\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.2, bidirectional=True)\n",
    "\n",
    "        # 定義全連接層\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim // 4)\n",
    "        self.fc2 = nn.Linear(hidden_dim // 4, input_dim)\n",
    "        self.fc3 = nn.Linear(input_dim, 1)\n",
    "\n",
    "        # 定義損失函數（Huber Loss）\n",
    "        # self.criterion = nn.HuberLoss(delta=self.delta)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # self.criterion = nn.L1Loss()\n",
    "        # self.criterion = log_cosh_loss\n",
    "\n",
    "    def log_cosh_loss(y_pred, y_true):\n",
    "        loss = torch.mean(torch.log(torch.cosh(y_pred - y_true)))\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隱藏狀態和細胞狀態\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(self.device)\n",
    "        residual = x\n",
    "        \n",
    "        # 前向傳播 LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 通過全連接層得到最終輸出\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out += residual\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)  # 使用 Huber Loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)  # 使用 Huber Loss\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=1e-2\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.9)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n"
     ]
    }
   ],
   "source": [
    "months = ['01','02','03','04','05','06','07','08', '09', '10']\n",
    "features = ['rain', 'raintime', 'solarpower', 'suntime', 'temp', 'uv']\n",
    "cwb_data_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "for month in months:\n",
    "    for feature in features:\n",
    "        with open(f'../cwbdata/{month}/{feature}-{month}.csv', 'r', encoding='utf-8') as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for row in reader:\n",
    "                if row[0].isdigit():\n",
    "                    cwb_data_dict[feature][month][row[0]] = row[1:]\n",
    "print(cwb_data_dict['rain']['01']['01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_cwb_data(month, day, loc): #0101\n",
    "    test_x = []\n",
    "    for hour in range(6, 18):\n",
    "        for minute in range(60):\n",
    "            try:\n",
    "                # 確保索引不超出範圍\n",
    "                newx = [\n",
    "                    float(cwb_data_dict['rain'][month][day][int(hour) + 1]),\n",
    "                    float(cwb_data_dict['raintime'][month][day][int(hour) + 1]),\n",
    "                    float(cwb_data_dict['solarpower'][month][day][int(hour) + 1]),\n",
    "                    float(cwb_data_dict['suntime'][month][day][int(hour) + 1]),\n",
    "                    float(cwb_data_dict['temp'][month][day][int(hour) + 1]),\n",
    "                    float(cwb_data_dict['uv'][month][day][int(hour) + 1]),\n",
    "                    loc\n",
    "                ]\n",
    "            except (IndexError, KeyError, ValueError, TypeError):\n",
    "                # 如果出現錯誤，使用默認值\n",
    "                newx = [0.0] * 7\n",
    "            test_x.append(\n",
    "                newx\n",
    "            )\n",
    "    return test_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_at_time(y_hat_original, hour, minute):\n",
    "    hour = int(hour)\n",
    "    minute = int(minute)\n",
    "    if hour < 6 or hour > 17:\n",
    "        raise ValueError(\"小時超出範圍，必須在 [6, 17] 之間\")\n",
    "    if minute < 0 or minute > 59:\n",
    "        raise ValueError(\"分鐘超出範圍，必須在 [0, 59] 之間\")\n",
    "    index = (hour - 6) * 60 + minute\n",
    "    \n",
    "    if index >= len(y_hat_original):\n",
    "        raise IndexError(f\"索引 {index} 超出 y_hat_original 長度 {len(y_hat_original)}\")\n",
    "    # 返回該時間點的預測值\n",
    "    return list(y_hat_original[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cwb2LocModel(\n",
       "  (lstm): LSTM(7, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=7, bias=True)\n",
       "  (fc3): Linear(in_features=7, out_features=1, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f'./saved_models/best-checkpoint-res-2-128-mae.ckpt'\n",
    "model = Cwb2LocModel.load_from_checkpoint(model_path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  # 將模型移動到 GPU（如果可用）\n",
    "model.eval()  # 切換模型到評估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_sample_output(id, model_cls=Cwb2LocModel):\n",
    "    # 解析 ID\n",
    "    month = id[4:6]\n",
    "    day = id[6:8]\n",
    "    hour = id[8:10]\n",
    "    minute = id[10:12]\n",
    "    loc = int(id[12:])\n",
    "    # print(loc)\n",
    "    \n",
    "    # 加載模型\n",
    "\n",
    "    \n",
    "    # 加載標準化器\n",
    "    with open(f'./scalar/x_scaler.pkl', 'rb') as f:\n",
    "        x_scaler = pickle.load(f)\n",
    "    with open(f'./scalar/y_scaler.pkl', 'rb') as f:\n",
    "        y_scaler = pickle.load(f)\n",
    "    \n",
    "    # 構建測試數據\n",
    "    test_x = collate_cwb_data(month, day, loc)  # 獲取測試數據 (shape: [max_len, num_features])\n",
    "    test_x = np.array(test_x, dtype=np.float32)  # 確保數據是 NumPy 格式\n",
    "    num_samples, num_features = test_x.shape\n",
    "    test_x = test_x.reshape(-1, num_features)  # 展平成 2D\n",
    "\n",
    "    # 正規化數據\n",
    "    test_x_normalized = x_scaler.transform(test_x)  # 對數據進行標準化\n",
    "    test_x_normalized = test_x_normalized.reshape(1, -1, num_features)  # 添加 batch 維度\n",
    "    \n",
    "    # 將數據轉換為 PyTorch 張量並移動到相應設備\n",
    "    test_x_tensor = torch.tensor(test_x_normalized, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 使用模型進行預測\n",
    "    with torch.no_grad():  # 禁用梯度計算以加速推理\n",
    "        y_hat = model(test_x_tensor)  # 模型預測\n",
    "        y_hat = y_hat.cpu().numpy()  # 將張量轉換為 NumPy 格式\n",
    "        y_hat = y_hat.reshape(-1, y_hat.shape[-1])  # 展平成 2D\n",
    "    \n",
    "    # 反正規化輸出\n",
    "    y_hat_original = y_scaler.inverse_transform(y_hat)  # 反正規化\n",
    "    preds = []\n",
    "    for i in range(int(minute), int(minute)+10):\n",
    "        preds.append(get_prediction_at_time(y_hat_original, hour, i))\n",
    "    return np.mean(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def fill_csv_with_predictions(csv_path, output_csv_path, model_cls):\n",
    "    import pandas as pd\n",
    "\n",
    "    # 讀取 CSV 文件\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 檢查是否包含必要的列\n",
    "    if '序號' not in df.columns or '答案' not in df.columns:\n",
    "        raise ValueError(\"CSV 文件必須包含 '序號' 和 '答案' 列\")\n",
    "    \n",
    "    # 遍歷每個序號進行預測\n",
    "    predictions = []\n",
    "    for seq_id in tqdm(df['序號'], desc=\"Processing Predictions\", unit=\"sample\"):\n",
    "        try:\n",
    "            # 使用模型進行預測\n",
    "            prediction = get_single_sample_output(str(seq_id), model_cls=model_cls)\n",
    "            \n",
    "            # 確保 prediction 是 float\n",
    "            if isinstance(prediction, (float, np.float32, np.float64)):\n",
    "                if prediction >= 0:\n",
    "                    predictions.append(prediction)\n",
    "                else:\n",
    "                    predictions.append(0.0)\n",
    "            else:\n",
    "                raise ValueError(f\"無效的輸出類型: {type(prediction)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"序號 {seq_id} 預測失敗，錯誤: {e}\")\n",
    "            predictions.append(\"ERROR\")  # 如果失敗則標記為 ERROR\n",
    "    \n",
    "    # 將預測結果填入答案列\n",
    "    df['答案'] = predictions\n",
    "    \n",
    "    # 將結果保存為新的 CSV 文件\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"預測結果已保存到 {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.59294\n"
     ]
    }
   ],
   "source": [
    "print(get_single_sample_output('20240101100001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Predictions:   0%|          | 0/9600 [00:00<?, ?sample/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Predictions: 100%|██████████| 9600/9600 [01:08<00:00, 139.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測結果已保存到 ./up5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fill_csv_with_predictions('./up.csv', './up5.csv', Cwb2LocModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
