{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidteng/anaconda3/envs/wsd/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, torch\n",
    "import lightning  as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load cwb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0.9947946687553407, 0.9947747071946897, 0.994766484862803, 0.994770173585678, 0.9947859451893126, 0.9948139714997057, 0.9948544243428545, 0.9949074755447569, 0.9949732969314115, 0.995052060328816, 0.9951439375629682, 0.9952491004598667, 0.9953677208455086, 0.995499970545893, 0.9956460213870167, 0.9958060451948788, 0.9959802137954769, 0.9961686990148085, 0.9963716726788725, 0.9965893066136661, 0.9968217726451879, 0.9970692425994352, 0.9973318883024068, 0.9976098815800999, 0.9979033942585134, 0.9982125981636445, 0.9985376651214918, 0.9988787669580527, 0.999236075499326, 0.9996097625713087, 1.0, 1.0004062179453885, 1.0008248799034332, 1.0012517077040823, 1.0016824231772867, 1.0021127481529957, 1.0025384044611587, 1.0029551139317252, 1.0033585983946454, 1.0037445796798683, 1.004108779617344, 1.0044469200370216, 1.0047547227688514, 1.0050279096427823, 1.0052622024887647, 1.0054533231367475, 1.0055969934166806, 1.0056889351585143, 1.0057248701921973, 1.0057005203476799, 1.0056116074549108, 1.0054538533438406, 1.0052229798444183, 1.0049147087865942, 1.0045247620003173, 1.0040488613155374, 1.003482728562204, 1.0028220855702674, 1.0020626541696762, 1.0012001561903807]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 定义月份和特征\n",
    "months = ['01','02','03','04','05','06','07','08', '09', '10']\n",
    "features = ['rain', 'raintime', 'solarpower', 'suntime', 'temp', 'uv']\n",
    "\n",
    "# 初始化 cwb_data_dict，四层嵌套：特征 -> 月份 -> 天数 -> 时间索引\n",
    "# 时间索引初始为小时（0-23），插值后为分钟（0-1439）\n",
    "cwb_data_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "# 读取气象数据\n",
    "for month in months:\n",
    "    for feature in features:\n",
    "        csv_path = f'../cwbdata/{month}/{feature}-{month}.csv'\n",
    "        try:\n",
    "            with open(csv_path, 'r', encoding='utf-8') as csv_file:\n",
    "                reader = csv.reader(csv_file)\n",
    "                for row in reader:\n",
    "                    if row[0].isdigit():\n",
    "                        day = int(row[0])\n",
    "                        for hour_index, value in enumerate(row[1:], start=0):\n",
    "                            if hour_index < 24:\n",
    "                                try:\n",
    "                                    cwb_data_dict[feature][int(month)][day][hour_index] = float(value)\n",
    "                                except (ValueError, TypeError):\n",
    "                                    cwb_data_dict[feature][int(month)][day][hour_index] = None  # 标记为无效值\n",
    "        except FileNotFoundError:\n",
    "            print(f\"文件未找到: {csv_path}\")\n",
    "\n",
    "# 初始化插值后的数据字典\n",
    "cwb_data_interp_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "\n",
    "def interpolate_minute_data(hourly_values):\n",
    "    \"\"\"\n",
    "    对一天的24小时数据进行每分钟插值，返回1440分钟的浮点数列表。\n",
    "    使用三次样条插值，并确保插值后的值不为负。\n",
    "    \"\"\"\n",
    "    # 已知的分钟位置（每小时的第30分钟）\n",
    "    known_minutes = np.array([h * 60 + 30 for h in range(24)])\n",
    "    known_values = np.array(hourly_values)\n",
    "    \n",
    "    # 创建所有分钟的索引\n",
    "    all_minutes = np.arange(1440)\n",
    "    \n",
    "    # 处理缺失值后进行插值\n",
    "    # 使用三次样条插值\n",
    "    try:\n",
    "        # 创建插值函数\n",
    "        spline = interp1d(known_minutes, known_values, kind='cubic', fill_value=\"extrapolate\")\n",
    "        interpolated = spline(all_minutes)\n",
    "    except Exception as e:\n",
    "        print(f\"插值失败: {e}\")\n",
    "        interpolated = np.zeros(1440)\n",
    "    \n",
    "    # 确保插值后的值不为负\n",
    "    interpolated = np.clip(interpolated, a_min=0, a_max=None)\n",
    "    \n",
    "    return interpolated.tolist()\n",
    "\n",
    "# 处理每个特征、每个月、每天的数据\n",
    "for feature in features:\n",
    "    for month in range(1, 11):  # months '01' to '10' correspond to 1 to 10\n",
    "        for day in cwb_data_dict[feature][month]:\n",
    "            # 获取24小时的值\n",
    "            hourly_values = [cwb_data_dict[feature][month][day].get(hour, None) for hour in range(24)]\n",
    "            \n",
    "            # 填充 None 值\n",
    "            for hour in range(24):\n",
    "                if hourly_values[hour] is None:\n",
    "                    # 查找前一个有效值\n",
    "                    prev = None\n",
    "                    for h in range(hour - 1, -1, -1):\n",
    "                        if hourly_values[h] is not None:\n",
    "                            prev = hourly_values[h]\n",
    "                            break\n",
    "                    # 查找后一个有效值\n",
    "                    next_val = None\n",
    "                    for h in range(hour + 1, 24):\n",
    "                        if hourly_values[h] is not None:\n",
    "                            next_val = hourly_values[h]\n",
    "                            break\n",
    "                    # 计算平均值\n",
    "                    if prev is not None and next_val is not None:\n",
    "                        hourly_values[hour] = (prev + next_val) / 2\n",
    "                    elif prev is not None:\n",
    "                        hourly_values[hour] = prev\n",
    "                    elif next_val is not None:\n",
    "                        hourly_values[hour] = next_val\n",
    "                    else:\n",
    "                        hourly_values[hour] = 0.0  # 无有效值，填充0.0\n",
    "            \n",
    "            # 进行插值\n",
    "            interpolated_minutes = interpolate_minute_data(hourly_values)\n",
    "            \n",
    "            # 将1440分钟的数据分成24个小时，每小时60分钟\n",
    "            for hour in range(24):\n",
    "                start_min = hour * 60\n",
    "                end_min = start_min + 60\n",
    "                cwb_data_interp_dict[feature][month][day][hour] = interpolated_minutes[start_min:end_min]\n",
    "                # cwb_data_interp_dict[feature][month][day][hour] = [cwb_data_dict[feature][month][day][hour]] * 60\n",
    "\n",
    "# 确保插值后的数据没有 None\n",
    "for feature in features:\n",
    "    for month in range(1, 11):\n",
    "        for day in cwb_data_interp_dict[feature][month]:\n",
    "            for hour in range(24):\n",
    "                minute_data = cwb_data_interp_dict[feature][month][day][hour]\n",
    "                if any([x is None for x in minute_data]):\n",
    "                    # 进一步处理可能的 None（理论上已处理完毕）\n",
    "                    cwb_data_interp_dict[feature][month][day][hour] = [0.0 if x is None else x for x in minute_data]\n",
    "\n",
    "# 打印一个示例\n",
    "print(cwb_data_dict['suntime'][5][15][11])  # 1月1日的1点的rain数据，60个浮点数\n",
    "print(cwb_data_interp_dict['suntime'][5][15][11])  # 1月1日的1点的rain数据，60个浮点数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cwb2LocModel(L.LightningModule):\n",
    "    def __init__(self, input_dim=47, hidden_dim=128, output_dim=1, learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        MLP 模型\n",
    "        - input_dim: 输入特征的维度\n",
    "        - hidden_dim: 隐藏层神经元数量\n",
    "        - output_dim: 输出维度（目标维度）\n",
    "        - learning_rate: 学习率\n",
    "        \"\"\"\n",
    "        super(Cwb2LocModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 定义全连接层\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 损失函数\n",
    "        self.criterion = nn.L1Loss()  # 可以改为 MSELoss 或其他损失函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,  # 初始学习率\n",
    "            weight_decay=1e-2               # 权重衰减\n",
    "        )\n",
    "        \n",
    "        # 学习率调度器\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            threshold=1e-4,\n",
    "            cooldown=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cwb2LocModel(\n",
       "  (fc1): Linear(in_features=47, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (criterion): L1Loss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f'./saved_models_v4/best-checkpoint-A.ckpt'\n",
    "model = Cwb2LocModel.load_from_checkpoint(model_path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  # 將模型移動到 GPU（如果可用）\n",
    "model.eval()  # 切換模型到評估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./up.csv')\n",
    "pred_date_list = []\n",
    "# pred_start_time = [9, 0]\n",
    "# pred_end_time = [16, 59]\n",
    "for seq_id in df['序號']:\n",
    "    seq_id = str(seq_id)\n",
    "    new = (int(seq_id[4:6]), int(seq_id[6:8]), int(seq_id[-2:]))\n",
    "    if new not in pred_date_list:\n",
    "        pred_date_list.append(new)\n",
    "# for s in pred_date_list:\n",
    "#     print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 9, 57], [1, 2, 9, 58], [1, 2, 9, 59], [1, 2, 10, 0], [1, 2, 10, 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_time_range(month, day, hour, minute):\n",
    "    result = []\n",
    "    for delta in range(-2, 3):\n",
    "        # 計算新的分鐘數\n",
    "        new_minute = minute + delta\n",
    "        new_hour = hour\n",
    "\n",
    "        # 處理跨小時\n",
    "        if new_minute < 0:\n",
    "            new_hour -= 1\n",
    "            new_minute += 60\n",
    "        elif new_minute >= 60:\n",
    "            new_hour += 1\n",
    "            new_minute -= 60\n",
    "\n",
    "        # 確保時間仍然在9:00到17:00範圍內\n",
    "        # if 9 <= new_hour <= 17:\n",
    "        result.append([month, day, new_hour, new_minute])\n",
    "\n",
    "    return result\n",
    "\n",
    "# 範例測試\n",
    "example = get_time_range(1, 2, 9, 59)\n",
    "print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoded Categories: [array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.11767022, -0.36995235, -0.48790407,  0.80765128, -1.89731916,\n",
       "       -0.8206524 , -0.11778042, -0.37022636, -0.4762824 ,  0.83127131,\n",
       "       -1.88887866, -0.81733107, -0.1178918 , -0.37049831, -0.46457977,\n",
       "        0.85471435, -1.8803706 , -0.81391606, -0.11800435, -0.37076801,\n",
       "       -0.45279961,  0.87797162, -1.87179808, -0.81040746, -0.11811817,\n",
       "       -0.37103554, -0.44094536,  0.90103431, -1.86316418, -0.8068055 ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 示例: 加载已保存的编码器\n",
    "with open('./scalar_v4/loc_encoder.pkl', 'rb') as f:\n",
    "    loc_encoder = pickle.load(f)\n",
    "\n",
    "# 确保编码器加载正确，打印支持的类别\n",
    "print(f\"One-Hot Encoded Categories: {loc_encoder.categories_}\")\n",
    "\n",
    "with open('./scalar_v4/x_scaler.pkl', 'rb') as f:\n",
    "    x_scaler = pickle.load(f)\n",
    "\n",
    "\n",
    "def extract_features(cwb_data_interp_dict, features, location, month, day, hour, minute):\n",
    "    try:\n",
    "        newx = [cwb_data_interp_dict[feature][month][day][hour][minute] for feature in features]\n",
    "        # newx.append(int(location))  # 添加 location 作为特征\n",
    "        # newx.append(int(hour))\n",
    "        # newx.append(int(minute))\n",
    "    except Exception as e:\n",
    "        print(f\"Error at {location}-{month}-{day} {hour}:{minute}: {e}\")\n",
    "        newx = [0.0] * (len(features) + 1)\n",
    "    return newx\n",
    "def collate_x_data(month, day, hour, minute, location, features):\n",
    "    \"\"\"\n",
    "    收集给定时间范围内的数据，完成标准化，并将 `location` 转换为 One-Hot Encoding。\n",
    "    \"\"\"\n",
    "    # 将 location 转为 One-Hot 编码\n",
    "    location_one_hot = loc_encoder.transform([[location]]).flatten()\n",
    "\n",
    "    # 初始化 x，包含 One-Hot 编码的 location\n",
    "    x_continuous = []  # 用于存储连续特征\n",
    "    time_range = get_time_range(month, day, hour, minute)\n",
    "\n",
    "    # 遍历时间范围，提取每个时间点的气象特征\n",
    "    for t_month, t_day, t_hour, t_minute in time_range:\n",
    "        x_continuous += extract_features(cwb_data_interp_dict, features, location, t_month, t_day, t_hour, t_minute)\n",
    "\n",
    "    # 转换为 NumPy 数组\n",
    "    x_continuous = np.array(x_continuous).reshape(1, -1)\n",
    "\n",
    "    # 对连续特征进行标准化\n",
    "    x_continuous = x_scaler.transform(x_continuous).flatten()\n",
    "\n",
    "    # 将 One-Hot 编码的 `location` 与标准化的连续特征拼接\n",
    "    x = np.concatenate([x_continuous, location_one_hot])\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(collate_x_data(1,2,7,50, 1, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616.8399047851562"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./scalar_v4/y_scaler.pkl', 'rb') as f:\n",
    "    y_scaler = pickle.load(f)\n",
    "def get_single_x_output(month, day, hour, minute, loc, features):\n",
    "    # 获取标准化后的输入特征\n",
    "    x_array = collate_x_data(\n",
    "        month, day, hour, minute, loc, features)\n",
    "\n",
    "    # 转换为 PyTorch Tensor\n",
    "    x_tensor = torch.tensor(x_array, dtype=torch.float32).unsqueeze(0).to(device)  # [1, feature_dim]\n",
    "\n",
    "    # 确保模型处于评估模式\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 模型预测\n",
    "        y_pred = model(x_tensor)  # [1, 1]\n",
    "        y_pred = y_pred.cpu().numpy()  # 转换为 NumPy 格式\n",
    "\n",
    "    # 逆标准化目标值\n",
    "    y_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "    return y_pred.flatten().tolist()[0]\n",
    "get_single_x_output(5,15,13,00,4,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9600/9600 [01:06<00:00, 144.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件已生成: ./submission.csv\n",
      "6207.800587481989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 平均每段时间的预测值作为答案\n",
    "from tqdm import tqdm\n",
    "submission_data = []\n",
    "error = 0\n",
    "for seq_id  in tqdm(df['序號']):\n",
    "    seq_id = str(seq_id)\n",
    "    month, day, hour, minute, loc = int(seq_id[4:6]), int(seq_id[6:8]), int(seq_id[8:10]), int(seq_id[10:12]), int(seq_id[-2:])\n",
    "    y_list = []\n",
    "    for i in range(minute, minute+10):\n",
    "        y_list.append(get_single_x_output(month, day, hour, i, loc, features))\n",
    "    # print(month, day, hour, time, loc)\n",
    "    y = sum(y_list)/len(y_list)\n",
    "    if y < 0:\n",
    "        error -= y\n",
    "        y = 0.0\n",
    "    submission_data.append([int(seq_id), y])\n",
    "\n",
    "# 转为 DataFrame\n",
    "submission_df = pd.DataFrame(submission_data, columns=['序號', '答案'])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "submission_df.to_csv('./upD-A4.csv', index=False)\n",
    "print(\"提交文件已生成: ./submission.csv\")\n",
    "print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
